{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#eb3483'> Data Wrangling - Time Series </font>\n",
    "In this module we explore a special type of data - time series (a.k.a. data related to times or dates). Time series data is pretty ubiquitous. Think of the stock market, weather data, or even your own bank statements - it's all data tied to specific dates and times. Dates and times deserve some extra special attention during your data wrangling process because they have some unique properties. Like numeric data they have a natural ordering (i.e. 3pm is after 2pm), but they also have additional structure (i.e. for a given time we have an hour, a day of the week, a year, a zodiac sign...etc.). \n",
    "\n",
    "This notebook first looks at how Python stores date/time data, and then dives deep into some cool functionality pandas has to play around with this data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> Datetime</font>\n",
    "We'll start by looking at python's basic way to deal with dates - the datetime object. We can load datetime functionality using the `datetime` package, and create a new datetime variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date #importing the datetime type from the datetime package (I know ... it's confusing!)\n",
    "\n",
    "#Let's make a date for July 1st 2020 (Canada day!)\n",
    "canada_day = datetime(year=2020, month =7, day=1)\n",
    "canada_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our datetime object has stored our year month and day. We can index to retrieve those variables using the same dot notation we've used in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_day.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify a time for our date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_day = datetime(year=2020, month =7, day=1, hour =13, minute = 30)\n",
    "canada_day.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the strftime (STRing Format TIME) method included with our datetime objects to print out our date as a nice string. We specify what we want our output string to look like by using special 'directives' (`%` followed by a letter). Think of directives as instructions (i.e. `%d` says put the day here), you can check out the plethora of formatting options [here](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is saying I want the string version of our date with\n",
    "#%B - the month (full name)\n",
    "#%d - the day (number)\n",
    "#%Y - the year\n",
    "#I've also thrown in a comma to make it look snazzy\n",
    "canada_day.strftime('%B %d, %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also go classic and do the American slash M/D/Y format\n",
    "canada_day.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datetime also has some handy functions that conveniently grab the current date/time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Right now:', datetime.now())\n",
    "print(\"Today's date:\", date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we're using the date object from datetime in the last line. Same idea as datetime but no time (can be handy when you only care about the day and not specific time). One of the cool things about working with dates in datetime objects is we can add and subtract dates - let's see how far Canada day is from fourth of july."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create a new datetime - the fourth of july for the yankees out there\n",
    "fourth_of_july = datetime(year=2020, month =7, day=4)\n",
    "\n",
    "#How far is fourth of july from canada day?\n",
    "holiday_difference = fourth_of_july - canada_day\n",
    "print('How far after canada day is fourth of july?', holiday_difference)\n",
    "print('Type of subtracted dates:', type(holiday_difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that when we add/subtract dates we get a new type of object: timedelta. It's what you would expect - a variable that stores the length of time between datetimes. We can even index into it and get the number of days in our timedelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_difference.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Quick Knowledge Check</font>\n",
    "1. Create a new datetime object for your next birthday. Print it out as a string with your choice of formatting (play around with different options!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate how many days away your birthday is from the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> Datetimes in Pandas </font>\n",
    "Datetime objects are great for individual dates (and provide a lot of flexibility/ease of use), but don't scale well to vectors of dates (i.e. columns in a dataframe). For that it's time to turn to our favorite coding bears - pandas! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'>Timestamps  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamp is the most basic form of time series data that Pandas has. It does exactly what the name describes: marks the exact moment in which the data was collected. \n",
    "\n",
    "While kaggle datasets and other online challenges are normally clean \"hourly\" or \"daily\" dataset, TimeStamps are how most data is normally collected in the wild! \n",
    "\n",
    "An event happens, and the time of the event is dumped into a database. \n",
    "\n",
    "One example of this would be... bitcoin! Now, whatever you may think about bitcoin, it is an excellent source of high-granularity data. Let's dive in! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/bitcoin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. We have this `Timestamp` column, that we can kind of parse by looking at it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Timestamp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can kind of understand this. Looks like Year, month, and day, then hours, minutes, then seconds ...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect a random row: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('One of the times in our dataset: %s' % data.Timestamp.iloc[3])\n",
    "print('Type of the Series (data.Time):  %s' % data.Timestamp.dtype)\n",
    "print('Type of a particular time:       %s' % type(data.Timestamp.iloc[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `pd.to_datetime` to parse the timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_as_a_timestamp = pd.to_datetime(data.Timestamp, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is it now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_as_a_timestamp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the column is in `datetime[ns]` format! That means the column is a timestamp (with precission in nanoseconds)\n",
    "\n",
    "Now we can compute statistics with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_as_a_timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_as_a_timestamp.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract days, months etcetera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_as_a_timestamp.dt.day.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because the column is a timestamp dtype, it has the `.dt` accessor with all of the timestamp related functions. Since pandas was created for stock trading data (which are timeseries), [there are lot of timestamp specific properties!](https://pandas.pydata.org/pandas-docs/stable/api.html#datetimelike-properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a toy dataset so that we can see some of the results side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame()\n",
    "new['date'] = time_as_a_timestamp\n",
    "new['day'] = new['date'].dt.day\n",
    "new['month'] = new['date'].dt.month\n",
    "new['year'] = new['date'].dt.year\n",
    "new['hour'] = new['date'].dt.hour\n",
    "new['minute'] = new['date'].dt.minute\n",
    "new['second'] = new['date'].dt.second\n",
    "new['day of the week'] = new['date'].dt.weekday\n",
    "new['quarter'] = new['date'].dt.quarter\n",
    "new['is it a leap year?'] = new['date'].dt.is_leap_year\n",
    "\n",
    "new.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas... is amazing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Different date formats  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you may be thinking _\"hang on, was that just because the strings were exactly in the way Pandas likes them?\"_\n",
    "\n",
    "It's a fair question, and the answer is No. Pandas' [`to_datetime`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html) has an `infer_datetime_format` argument which is amazingly good, and can for the most part figure out what you need from it. \n",
    "\n",
    "Let's put it to the test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little function to sanity check our dates\n",
    "def sanity_check(dates):\n",
    "    # go ahead Pandas, guess my date format! \n",
    "    inferred_dates = pd.to_datetime(dates, infer_datetime_format=True)\n",
    "    \n",
    "    # Print out the results \n",
    "    print('Our first day is   5,    and was infered as %0.0f' % inferred_dates.iloc[0].day)\n",
    "    print('Our first month is 4,    and was infered as %0.0f' % inferred_dates.iloc[0].month)\n",
    "    print('Our first year is  2007, and was infered as %0.0f' % inferred_dates.iloc[0].year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with an easy one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_dates = pd.Series(['04/05/2007',  # <-- April 5th, 2007\n",
    "                            '04/13/2006', \n",
    "                            '12/27/2014'])\n",
    "\n",
    "sanity_check(american_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we separate them with hyphens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyphen_separated_dates = pd.Series(['04-05-2007',  # <-- April 5th, 2007\n",
    "                            '04-13-2006', \n",
    "                            '12-27-2014'])\n",
    "\n",
    "sanity_check(hyphen_separated_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the year in a weird way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_year = pd.Series(['04-05-07',  # <-- April 5th, 2007\n",
    "                        '04-13-06', \n",
    "                        '12-27-14'])\n",
    "\n",
    "sanity_check(short_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eh... english? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_in_english = pd.Series(['April 5th, 2007',  # <-- April 5th, 2007\n",
    "                            'April 13th, 2006', \n",
    "                            'December 27th, 2014'])\n",
    "\n",
    "sanity_check(dates_in_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! So, european dates should be easy... right? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "european_dates = pd.Series(['05/04/2007',   # <-- April 5th, 2007\n",
    "                            '13/04/2006', \n",
    "                            '27/12/2014'])\n",
    "\n",
    "sanity_check(european_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait... what? It got the day and month mixed up! \n",
    "\n",
    "It turns out Pandas can infer lots of things, but Europe isn't it's strenght. Even though the second and third line clearly indicate that the month is in the middle (the 13'th can't be a month), it still gets confused. \n",
    "\n",
    "And here is where line 2 of [The Zen of Python](https://www.python.org/dev/peps/pep-0020/#id3) comes in:\n",
    "> Explicit is better than implicit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_dates = pd.to_datetime(european_dates, \n",
    "                                dayfirst=True)  # <--- explicit! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our first day is   5,    and was infered as %0.0f' % inferred_dates.iloc[0].day)\n",
    "print('Our first month is 4,    and was infered as %0.0f' % inferred_dates.iloc[0].month)\n",
    "print('Our first year is  2007, and was infered as %0.0f' % inferred_dates.iloc[0].year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By being explicit, we can parse arbitrarily crazy dates, following python [date string formatting syntax](http://strftime.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates_in_quackland = pd.Series(['05_quack_2007$04',   # <-- April 5th, 2007, in quack_timesystem\n",
    "                                '13_quack_2006$04',    \n",
    "                                '27_quack_2014$12'])\n",
    "\n",
    "inferred_dates = pd.to_datetime(dates_in_quackland, \n",
    "                                format='%d_quack_%Y$%m')  # <--- %d is day, %m is month, %Y is 4 digit year\n",
    "\n",
    "print('Our first day is   5,    and was infered as %0.0f' % inferred_dates.iloc[0].day)\n",
    "print('Our first month is 4,    and was infered as %0.0f' % inferred_dates.iloc[0].month)\n",
    "print('Our first year is  2007, and was infered as %0.0f' % inferred_dates.iloc[0].year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Quick Knowledge Check</font>\n",
    "1. Time to practice converting some dates! Write code that converts the following series into datetimes columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canadian_dates = pd.Series(['July 24, 2020 eh!',\n",
    "                           'October 6, 2020 eh!',\n",
    "                           'January 3, 2019 eh!',])\n",
    "\n",
    "#Convert the canadian dates series here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that the first two digit number is month (you can tell because the second one >12)\n",
    "farm_dates = pd.Series(['Oink 2020 Moo 12 Baa 18 Cluck 14:00',\n",
    "                        'Oink 2020 Moo 2 Baa 3 Cluck 1:00',\n",
    "                        'Oink 2004 Moo 7 Baa 9 Cluck 21:00'])\n",
    "#Convert the farm dates series here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'>Datetime Indices </font>\n",
    "Where pandas really shines is when we set a datetime data as our index (it's generally good practice to do this when you have time seriees data for reasons that will become apparent soon). So let's start by setting our timestampl column as our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Timestamp = pd.to_datetime(data.Timestamp, infer_datetime_format=True)\n",
    "\n",
    "data = data.set_index('Timestamp',    # <---- Set the index to be our timestamp data  \n",
    "                      drop=True)      # <---- drop the original column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's take a peak to make sure we did this right\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also sort our dataframe by the time index (good practice for time series data!)\n",
    "data = data.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data with the timeseries index we can do some really cool indexing (pandas is ... amazing!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get all the data for Jan 17th\n",
    "data.loc['Jan 17th 2018'].head()   # <--- wait, you can do that???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or how about all the January data?\n",
    "data.loc['Jan 2018'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can even look at data between dates\n",
    "data.loc['01/15/2018':'01/22/2018']  # <--- remember, American dates are less error prone in Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially we can slice our data by using dates, and pandas even let's us use date different formats. The beauty of this is that it seems perfectly natural (of course we should be able to just pull all of january's data without fancy index conditions), but for anyone coming from a different coding language you'll realize this is bonkers crazy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'>Resampling Data </font>\n",
    "Sometimes we might get data at a really granular level (i.e. microsecond) and want to take a step back and look at a larger time frequency (i.e. days). Let's think about some of our bitcoin data fields. The price on Jan 17th, at 3h00m00s makes sense (since its an event, something that happened). But the volume \"in that moment\"? It's a bit non-sensical (you dont have a number of transactions in a snap second, *you have them over a period*). Some datasets (this one probably included) will treat data as being \"since the last timestamp\", but real world data may not be so forgiving. \n",
    "\n",
    "Counting using timestamps is like asking _how many people went into McDonnals at an exact moment_. Probably none. It does't tell us much. We' think in people \"per minute\", or \"per hour\". To _resample_ our data at a different time frequency, we can use the [resample](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi3jfnKgNnaAhUGvBQKHRCwBd4QFggpMAA&url=https%3A%2F%2Fpandas.pydata.org%2Fpandas-docs%2Fstable%2Fgenerated%2Fpandas.DataFrame.resample.html&usg=AOvVaw1le9agxvLanaQp9zlNYG9Y) function.\n",
    "\n",
    "Let's start by looking at our bitcoin data in 5 minute intervals. All we have to do is call the resample method on our series and specify the interval (5 min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Volume_(Currency)'].resample('5 min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm what are we getting back - that doesn't look like numbers! It's actually a new \"resampler\" object (very similar to 'groupby' objects in pandas), which is just a series with some extra information about how to apply functions to it (i.e. when we apply sum it'll apply it to 5 minute time intervals of our dataset). Which means, to actually get some numbers we need to specify how we're going to map our 5 minute interval data to one number. Let's use sum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Volume_(Currency)'].resample('5 min').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boo ya - now we have the total volume (currency) traded in 5 minute time buckets. We could have also chosen other aggregation functions (like max, mean, min...etc.) - try it out yourself!\n",
    "\n",
    "We can specify our resampling windows using special characters just like our string formatting (check-out the full list of frequency code names [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)). For example, let's look at the max volume in every 2 week interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['Volume_(Currency)'].resample('2W').max().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Quick Knowledge Check</font>\n",
    "1. What's the higheset bitcoin open price every day in january? (Hint first get all the january data, and then apply our resampling function for days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Timeshifts </font>\n",
    "Sometimes we might want to shift our dates by a fixed amount. For example, what if our \"timestamp\" column was actually when the bitcoin data was reported, not when it happened (i.e. all of our dates are off by 2 weeks)? For that we can use the `tshift` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's remember what our dates were originally (starts at jan 1!)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shift our data by 2 weeks. We can do this by specifying the frequency (i.e. the time unit we're using for our shift) as weeks, and our periods as 2 (i.e. how many time units we want to move it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tshift(periods=2, freq = 'W').head() #<--- 2 W = 2 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We could also shift it by 14 days and get the same results\n",
    "data.tshift(periods=14, freq = 'D').head() #<--- 14 D = 14 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet - our data is shifted! To make these changes stick we'd have to assign the shifted data to our data object - but we'll leave it as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Quick Knowledge Check</font>\n",
    "1. Can you shift our data by three quarter-years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Rolling Windows </font>\n",
    "\n",
    "Rolling windows do what their name suggest: aggregate of the previous X periods (and, for instance, take the mean). They are very useful to smooth choppy timeseries and be less reactive to noise. \n",
    "\n",
    "We can choose to center the window (look back and forward), but in general we only want to take into account information from the past, so we should use `center=False` (which is the default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say it's December 18th 2017, in the early morning, and we are at our terminal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Midnight and a bit... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['Dec 18th 2017 00:08:00':'Dec 18th 2017 00:12:00', 'Weighted_Price'].plot(figsize=(16, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgflip.com/29iucd.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A few minutes pass... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['Dec 18th 2017 00:12:00':'Dec 18th 2017 00:15:00', 'Weighted_Price'].plot(figsize=(16, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.redditmedia.com/VE5dgdjQ8FKZ47gdxJdQ07q36bsZVyhvAmllvLdtTnI.jpg?w=534&s=ce869cd0d8630cd420af7fa72b3c296d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A few more minutes... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['Dec 18th 2017 00:15:00':'Dec 18th 2017 00:18:00', 'Weighted_Price'].plot(figsize=(16, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgflip.com/29iucd.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think you get the picture. What's going on is that we're being extremely reactive to noise, and missing the underlying process. What is in fact going on is that we are in a free-fall, but it might not be obvious unless we look at the slightly broader picture. \n",
    "\n",
    "In other words, assuming there is an underlying process, we can assume the recent past should carry some weight. How much weight? A rolling [window](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rolling.html) of weight! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first hour of Dec 18th 2017, as seen by traders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['Dec 18th 2017 00:00:00':'Dec 18th 2017 01:00:00', 'Weighted_Price'].plot(figsize=(16, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first hour of Dec 18th 2017, as seen by a rolling window of 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just the raw data, so we can apply a rolling window on it  \n",
    "first_hour = data.loc['Dec 18th 2017 00:00:00':'Dec 18th 2017 01:00:00', 'Weighted_Price']\n",
    "\n",
    "# notice the window size as a parameter of rolling, feel free to mess around with that parameter \n",
    "# and the center set to False. That's because we don't want to use data from the future! \n",
    "# Also notice how we use the mean. We can use many others. Try changing it! \n",
    "window_size = 10\n",
    "first_hour_rolling_window = first_hour.rolling(window=window_size, center=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these look like? A rolling window of 10 basically calculates the average bitcoin price in 10 minutes interval (so the average price between 00:00 and 00:10, the average price between 00:01 and 00:11, the avg price between 00:02 and 00:12, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot these together \n",
    "first_hour_rolling_window.plot(figsize=(16, 8), \n",
    "                               color='b',\n",
    "                               label=f'rolling_window = {window_size}');\n",
    "first_hour.plot(figsize=(16, 8), label='raw data', alpha=.7, ls='-', color='orange');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Quick Knowledge Check</font>\n",
    "1. Can you get the maximum close price in a rolling window of 2 weeks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
