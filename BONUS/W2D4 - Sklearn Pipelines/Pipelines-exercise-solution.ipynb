{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv(\"data/movies.1.initial_process.csv\")\n",
    "movies = movies[movies.status==\"Released\"]\n",
    "del movies[\"status\"]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Pipeline that process the dataset. You have to make sure you deal accordingly with numerical, categorical and text variables. (Note: you dont have to use them all!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = movies.select_dtypes(np.number).columns\n",
    "categorical_cols = movies.select_dtypes(object).drop(columns=[\n",
    "                            \"belongs_to_collection\",\n",
    "                            \"title\",\n",
    "                            \"release_date\"\n",
    "    ]).columns\n",
    "date_col = [\"release_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline, make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import ColumnSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "numerical_pipeline = make_pipeline(\n",
    "    ColumnSelector(cols=numerical_cols),\n",
    "    imputer,\n",
    "    scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline.fit_transform(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "categorical_pipeline = make_pipeline(\n",
    "    ColumnSelector(cols=categorical_cols),\n",
    "    OneHotEncoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline.fit_transform(movies).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline = make_union(\n",
    "    categorical_pipeline,\n",
    "    numerical_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: you could probably use the release date year as a categorical like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(movies.release_date).dt.year.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processing_pipeline.fit_transform(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Ridge estimator to predict a movies revenue based on the other features. What is the optimal value of alpha to minimize the RMSE? *Hint*: You can use validation curves to figure it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"revenue\"\n",
    "numerical_cols_no_revenue = movies.drop(columns=target).select_dtypes(np.number).columns\n",
    "\n",
    "numerical_pipeline_no_revenue = make_pipeline(\n",
    "    ColumnSelector(cols=numerical_cols_no_revenue),\n",
    "    imputer,\n",
    "    scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline_no_revenue = make_union(\n",
    "    categorical_pipeline,\n",
    "    numerical_pipeline_no_revenue\n",
    ")\n",
    "movies_with_revenue = movies[movies.revenue.notnull()]\n",
    "processed_data_no_revenue = processing_pipeline_no_revenue.fit_transform(movies_with_revenue)\n",
    "target_revenue = movies_with_revenue.revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_no_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_alpha = np.linspace(0.001, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse_cv(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.sqrt(mean_squared_error(y_pred, y))\n",
    "\n",
    "estimator = Ridge()\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    estimator, \n",
    "    processed_data_no_revenue,\n",
    "    target_revenue,\n",
    "    param_name=\"alpha\", \n",
    "    param_range=range_alpha,\n",
    "    cv=3, \n",
    "    scoring=rmse_cv,\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.abs(np.mean(train_scores, axis=1))\n",
    "test_scores_mean = np.abs(np.mean(test_scores, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range_alpha, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "plt.plot(range_alpha, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "plt.title(\"Validation Curve: Ridge alpha value\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Root Mean Squared Error (RMSE)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the training score increases but the test score flattens out around $\\alpha=90$. Since what we care the most is about the test score (the training score is nice but we care more about how the model generalizes on unseen data) we can use that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(Ridge(alpha=90),\n",
    "                          processed_data_no_revenue,\n",
    "                          target_revenue,\n",
    "                          scoring=rmse_cv,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1\n",
    "                         ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember when we did exploratory data analyses and we groupd the numerical variables into quintiles? That is a valid technique used in Machine Learning to expand a dataset, it is called [Binning or Bucketing](http://blog.yhat.com/tutorials/5-Feature-Engineering.html).\n",
    "\n",
    "### Create your own transformer that given a numerical variable and a number of buckets returns the specificed quartile (so if we choose buckets = 4, it would return 1, 2,3 or 4 depending on each observation being on the 1st, 2nd, 3rd or 4th quartile).\n",
    "\n",
    "### Try putting your bucket transformer into a pipeline to make sure it works, and check if it improves the performance of your model.\n",
    "\n",
    "**Hint**: You can use `ColumnSelector` as a template, and you can check pandas `qcut` for the actual binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformer must work with numpy arrays, and I would like it also to work with pandas dataframes as inputs. The output will be a numpy array.\n",
    "\n",
    "I found that for some columns I got the error:\n",
    "\n",
    "Which can be solved by setting the parameter `duplicates=\"drop\"` to qcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class QuantileBinner(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Transform a column and groups it into a specified number of buckets\n",
    "    \"\"\"\n",
    "    def __init__(self, bins):\n",
    "        self.bins = bins\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        output = pd.DataFrame()\n",
    "        if not hasattr(X, 'loc'):\n",
    "            # if the input doesnt have the method loc is a numpy array\n",
    "            input_data = pd.DataFrame(X)\n",
    "        else:\n",
    "            #only pandas dataframes have the method loc\n",
    "            input_data = X\n",
    "        for column in input_data.columns:\n",
    "            output = pd.concat([output, pd.qcut(\n",
    "                                            input_data[column],\n",
    "                                            self.bins,\n",
    "                                            duplicates=\"drop\").cat.codes], \n",
    "                                   axis=1)  \n",
    "        return output.values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner = QuantileBinner(bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test  that it works with numpy arrays and pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner.fit_transform(movies[[\"budget\", \"popularity\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner.fit_transform(movies[[\"budget\", \"popularity\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline_no_revenue_buckets = make_pipeline(\n",
    "    ColumnSelector(cols=numerical_cols_no_revenue),\n",
    "    imputer,\n",
    "    scaler,\n",
    "    binner\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline_no_revenue_buckets = make_union(\n",
    "    categorical_pipeline,\n",
    "    numerical_pipeline_no_revenue_buckets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_no_revenue_buckets = processing_pipeline_no_revenue_buckets.fit_transform(movies_with_revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_no_revenue_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(Ridge(alpha=90),\n",
    "                          processed_data_no_revenue_buckets,\n",
    "                          target_revenue,\n",
    "                          scoring=rmse_cv,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1\n",
    "                         ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in this case it does not improve the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
