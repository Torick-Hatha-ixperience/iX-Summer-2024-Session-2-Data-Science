{"cells":[{"cell_type":"markdown","metadata":{"id":"gwRqevkk6h1l"},"source":["# <font color='#eb3483'> Transforming Pandas DataFrames and Series </font>"]},{"cell_type":"markdown","metadata":{"id":"Yn5rIxO36h1p"},"source":["Where pandas really shines is in it's ability to transform data - allowing you to tidy up a dataset in just a few lines of code. In this notebook, we'll be exploring this functionality. Remember, most of a data scientist's time is spent cleaning and transforming data!\n","\n","In this notebook we will cover:\n","\n","1. Removing rows and columns\n","1. Mathematical operations\n","1. Naming operations\n","1. Aggregations\n","\n","We're going to work with the AirBnB dataset again, but only a few columns. When we load a dataframe from the csv file, we can specify the columns we want to use with `usecols`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kJV3xO56h1q"},"outputs":[],"source":["import pandas as pd\n","columns = [\"room_id\", \"host_id\", \"room_type\", \"neighborhood\", \"reviews\", \"overall_satisfaction\",\"accommodates\", \"bedrooms\", \"price\"]\n","df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"yPePvETP6h1s"},"source":["## <font color='#eb3483'> 1. Removing Rows and Columns </font>\n","To remove rows and columns, we can use dataframe's `.drop` method. By default `.drop` removes rows based on the index value (**not** row position).\n","\n","Drop has two important arguments:\n","* `index/columns`: Specify the index values and/or column names that you want to drop.\n","* `inplace`: With this argument, you can chose if you want to transform the original dataframe or if you want the drop function to return a copy of the transformed dataframe. The default value is ```False```.\n","\n","To find out more on the ```.drop``` method and its arguments, type ```?df.drop```."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUJwuz0a6h1s"},"outputs":[],"source":["df.drop(index = [6499, 17031]) # drops the rows where room_id is 6499 or 17031 (this is the index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WT3bwiGb6h1t"},"outputs":[],"source":["?df.drop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59pb5Og46h1t"},"outputs":[],"source":["df.drop(columns=[\"reviews\", \"price\"]) # drops two columns"]},{"cell_type":"markdown","metadata":{"id":"y0b_Vi7W6h1u"},"source":["You can drop rows and columns at the same time. e.g.\n","\n","```python\n","df.drop(index = [6499, 17031], columns=[\"reviews\", \"price\"])\n","```\n","\n","Columns can also be dropped using Python's ```del``` function:\n","```python\n","del df['reviews']\n","```\n","Note that this is an \"inplace\" operation, so it modifies the original dataframe, but does not return anything. It can only be applied to one column at a time and only when the column name is provided inside square brackets.\n","\n","This will work:\n","```python\n","del df['reviews'], df['price']\n","```\n","\n","These will **not** work:\n","```python\n","del df[['reviews','price']]\n","del df.reviews\n","```"]},{"cell_type":"markdown","metadata":{"id":"oOg2_hrQ6h1v"},"source":["## <font color='#eb3483'> 2. Mathematical Operations </font>"]},{"cell_type":"markdown","metadata":{"id":"76L_0NlL6h1w"},"source":["Very often we want to manipulate a column to get something that makes more sense. Maybe getting a value per hour, or price per week or turning a birthdate into an age etc."]},{"cell_type":"markdown","metadata":{"id":"URm_10da6h1w"},"source":["### <font color='#eb3483'>  Multiplication </font>\n","\n","You can either use the `*` or the `.multiply()` method to multiply two columns or multiply columns by a number.\n","\n","For example, we can calculate the weekly price for the listings:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5pszkLv6h1x"},"outputs":[],"source":["df[\"price_per_week\"] = df.price * 7 # or df[\"price_per_week\"] = df.price.multiply(7)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"dX95_EYJ6h1x"},"source":["### <font color='#eb3483'>   Division </font>\n","We can use either `/` or the `.divide()` to divide.\n","\n","For example, we can calculate the number of people per bedroom:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGSnr8Ax6h1x"},"outputs":[],"source":["df[\"people_per_bedroom\"] = df.accommodates / df.bedrooms # or df.accommodates.divide(df.bedrooms)\n","df.head(10)"]},{"cell_type":"markdown","metadata":{"id":"YAfFo-2g6h1y"},"source":["<font color='#eb3483'> Exercise: </font> Try adding or subtracting columns."]},{"cell_type":"markdown","metadata":{"id":"wBgH12fd6h1y"},"source":["## <font color='#eb3483'> 3. Naming Operations </font>"]},{"cell_type":"markdown","metadata":{"id":"r0-sRsgt6h1y"},"source":["We can change the name of the columns by changing the column names list `df.columns`. For example, we can rename the columns and make them capitalized."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WS4syBCz6h1z"},"outputs":[],"source":["new_column_names = df.columns.str.title() # converts the current column names to title case\n","df.columns = new_column_names\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"eLWDA8WD6h1z"},"source":["Alternatively, we can use the ```.rename``` method to rename either the row indices (with ```index=...```) or column names (with ```columns=...```). In both cases, we provide a dictionary that maps from the old name (dict key) to the new name (dict value). For example:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX2JkEOg6h1z"},"outputs":[],"source":["df.rename(columns = {\"Host_Id\": \"My_Funky_New_Name\"}) # could use inplace=True to modify original"]},{"cell_type":"markdown","metadata":{"id":"x1ya_Oz_6h10"},"source":["### <font color='#eb3483'>  Replace </font>"]},{"cell_type":"markdown","metadata":{"id":"zrRcxbHR6h10"},"source":["`.replace` allows us to replace values in the data (not the indices). For example, if we want to change the numerical values in the ```Overall_Satisfaction``` column to an ordinal scale we can do it by passing a dictionary to ```.replace``` in much the same way as we did for ```.rename```:"]},{"cell_type":"markdown","metadata":{"id":"TliqOw--6h10"},"source":["By default  `replace` replaces the values in all the columns. We should rather replace values only in the column we need."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"vBkVUulU6h10"},"outputs":[],"source":["df1 = df.Overall_Satisfaction.replace(\n","    {\n","        5:\"Best\",\n","        4: \"Good\",\n","        3: \"OK\",\n","        2: \"Not so great\",\n","        1: \"Worst\",\n","        0: \"No Information\"\n","    })"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKAP0_2d6h11"},"outputs":[],"source":["df1"]},{"cell_type":"markdown","metadata":{"id":"UDy168IB6h11"},"source":["## <font color='#eb3483'> 4. Aggregations </font>\n","The goal of aggregations is to allow us to get an aggregated view of sub-sections of our data. Before we begin, let's read in our data again to erase all the edits that we may have made above:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C6IzF4T16h11"},"outputs":[],"source":["df = pd.read_csv(\"data/airbnb.csv\", usecols=columns)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"BH3Gghe46h11"},"source":["### <font color='#eb3483'>  Groupby </font>"]},{"cell_type":"markdown","metadata":{"id":"ozeqGK-S6h11"},"source":["`groupby` allows us to group the dataframe based on its features.\n","\n","More precisely, Pandas' ```groupby``` enables a process called [split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/groupby.html).\n","* **split**: Separates the dataframe based on the specified groups\n","* **apply**: Applies a function to each one of the groups\n","* **combine**: Combines the results into a new dataframe\n","\n","For example, if we want to know how many listings there are in each neighborhood. This means that for every ```neighborhood``` (the \"group\"), we want to count up the unique values of ```room_id```.\n","\n","We start by grouping the data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBaaPUkf6h11"},"outputs":[],"source":["df.groupby(\"host_id\")"]},{"cell_type":"markdown","metadata":{"id":"ac_s_AwA6h12"},"source":["This returns a `DataFrameGroupBy ` object, which is a special dataframe object that separates the dataframe by group."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izxcYKzZ6h12"},"outputs":[],"source":["df.nunique() # gives you the number of unique values in each column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wz4fKWTc6h12"},"outputs":[],"source":["df.groupby(\"neighborhood\").nunique() # gives you the number of unique values in each column BY group"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2Msk_U_6h12"},"outputs":[],"source":["# just for the \"room_id\" column:\n","df.groupby(\"neighborhood\").room_id.nunique()"]},{"cell_type":"markdown","metadata":{"id":"unriX0sJ6h12"},"source":["By default, the columns we use to group become the index, if we want them to stay as columns we can use the argument `as_index = False`."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"BNXfj-kw6h12"},"outputs":[],"source":["df.groupby(\"neighborhood\", as_index=False).room_id.nunique()"]},{"cell_type":"markdown","metadata":{"id":"qwFtZsJf6h12"},"source":["<font color='#eb3483'> Exercise: </font> Calculate the average listing price by room type and host. **Hint:** Use the ```.mean()``` method to get the average (in place of ```.nunique()``` above)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vY3kNfjv6h13"},"outputs":[],"source":["df.groupby([\"room_type\",\"host_id\"], as_index=False).price.mean()"]},{"cell_type":"markdown","metadata":{"id":"ZrLI_EwT6h13"},"source":["We can apply any function to a grouped dataframe and pandas will pass the function on to the underlying split dataframes under the hood:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eG4O_nQd6h13"},"outputs":[],"source":["df.groupby([\"neighborhood\"]).price.describe()"]},{"cell_type":"markdown","metadata":{"id":"yGZbQd1c6h13"},"source":["### <font color='#eb3483'>  Aggregate </font>\n","\n","We have seen how to apply in-built methods like ```.sum``` and ```.mean``` to groups in a dataframe. What if we want to apply some other funky functions to each group, possibly ones that we have written ourselves? The pandas `aggregate` method allows us to do just that!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eras-kn66h13"},"outputs":[],"source":["def funky(x):\n","    return (min(x)+max(x))/2 # this returns a single number\n","\n","df.groupby([\"neighborhood\"]).price.aggregate(funky)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"IZgAEA5b6h13"},"outputs":[],"source":["df.groupby([\"neighborhood\"]).price.aggregate([min, funky, max]) # multiple functions all at once!"]},{"cell_type":"markdown","metadata":{"id":"ptQrmWLh6h13"},"source":["The `aggregate` function even let's us specify what columns we want to apply each aggregation function to using a dictionary:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOFipJaC6h13"},"outputs":[],"source":["df.groupby([\"neighborhood\"]).aggregate({'price': [funky, max], 'accommodates':min})"]},{"cell_type":"markdown","metadata":{"id":"tv27TlgP6h13"},"source":["### <font color='#eb3483'> Transform </font>\n","\n","The `transform` function allows us to apply a function to the grouped data without aggregation. For example, what if we wanted to center the price of each listing to see it's price relative to the average price in each neighbourhood?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0t1DN6_n6h14"},"outputs":[],"source":["def normalize(x):     # x is a single column in the dataframe\n","    return x-x.mean() # this returns a series of the same length as x\n","\n","df['norm_price'] = df.groupby([\"neighborhood\"])['price'].transform(normalize)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"DojJ_gWt6h14"},"source":["### <font color='#eb3483'> Apply </font>\n","\n","The ```apply``` function extends the functionality of `aggregate` and `transform` by allowing you to apply a function to **multiple** columns from the split up dataframes. It can return a single value for each group (like `aggregrate`) or a transformed series (like `transform`). It is the best of both worlds!\n","\n","Let's say we wanted to get the average price per person accommodated for each neighbourhood? That is, we get a **single number** for each neighborhood..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3Boc0NB6h14"},"outputs":[],"source":["def AvePricePerAccom(x):                            # x is a dataframe for a specific group\n","    return (x['price']/x['accommodates']).mean()    # this returns a single value\n","\n","df.groupby([\"neighborhood\"]).apply(AvePricePerAccom)"]},{"cell_type":"markdown","metadata":{"id":"SScySD6h6h14"},"source":["Below we compute the normalized price per person for each neighborhood. The function returns a **series** for each neighborhood..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jur2C8aJ6h14"},"outputs":[],"source":["def NormPricePerAccom(x):                                           # x is a dataframe for a specific group\n","    return (x['price']-x['price'].mean())/x['accommodates']         # this returns a series\n","\n","df.groupby([\"neighborhood\"]).apply(NormPricePerAccom)"]},{"cell_type":"markdown","metadata":{"id":"kyX6POH56h14"},"source":["### <font color='#eb3483'>  Crosstab </font>"]},{"cell_type":"markdown","metadata":{"id":"h9boeZ8V6h14"},"source":["`pd.crosstab` allows us to cross tabulate two columns in our dataset and returns the number/proportion of observations that fall into each cell in the resulting table."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wr7FCiYj6h14"},"outputs":[],"source":["pd.crosstab(df.neighborhood, df.room_type)"]},{"cell_type":"markdown","metadata":{"id":"aPc0PZmW6h14"},"source":["We can use the argument `normalize` to get percentages instead of totals:\n","- `normalize=\"all\"` returns total percentages (% of the total dataframe)\n","- `normalize=\"index\"` returns percentages per row\n","- `normalize=\"columns\"` returns percentages per column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9Ig5ZhM6h14"},"outputs":[],"source":["pd.crosstab(df.neighborhood, df.room_type, normalize=\"all\").head()"]},{"cell_type":"markdown","metadata":{"id":"le30qKfd6h14"},"source":["Now we can see the percentage of listings per neighborhood broken down by room type:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiMtrwn26h15"},"outputs":[],"source":["pd.crosstab(df.neighborhood, df.room_type, normalize=\"index\").head()"]},{"cell_type":"markdown","metadata":{"id":"tktM9Gyp6h15"},"source":["And we can see how many of each room type are on each neighborhood:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4elXBvCq6h15"},"outputs":[],"source":["pd.crosstab(df.neighborhood, df.room_type, normalize=\"columns\").head()"]},{"cell_type":"markdown","metadata":{"id":"VOKMqvSf6h15"},"source":["### <font color='#eb3483'>  Pivot Table </font>\n","\n","The `.pivot_table` method performs the same function as pivot tables in Excel. It turns rows into columns based on the values on the columns (that is, it \"pivots\" the data).\n","\n","This function has different arguments:\n","\n","- `index`: the columns whose values should become rows\n","- `columns`: the columns whose values should become columns\n","- `values`: the columns we want to aggregate\n","- `aggfunc`: the aggregate function applied to the values (mean by default)"]},{"cell_type":"markdown","metadata":{"id":"xAt7TNB86h15"},"source":["For example, if we want to calculate the average satisfaction by ```room_type``` for each ```neighborhood```:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssQjRxzf6h15"},"outputs":[],"source":["df = pd.read_csv(\"data/airbnb.csv\", usecols=columns, index_col=\"room_id\").sort_index()\n","df.pivot_table(index=\"neighborhood\",\n","               columns='room_type',\n","               values='overall_satisfaction',\n","               aggfunc='mean').head()"]},{"cell_type":"markdown","metadata":{"id":"hSVrWuKH6h15"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"id":"Qg4CG2Hp6h15"},"source":["# <font color='#eb3483'> LET'S PRACTICE! </font>\n","\n","# <font color='#eb3483'> Transforming Pandas DataFrames and Series  </font>\n","\n","Work on these excercises for 10 mins (or for homework depending on how well we do with time)"]},{"cell_type":"markdown","metadata":{"id":"kt_DIib26h15"},"source":["For these exercises we are going to use a new dataset, the 2016 US Primary elections (`primary_results.csv` in our data folder). Start by importing pandas and reading in our data:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiSZXA2_6h15"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"vabohovk6h15"},"source":["The dataset has the following columns:\n","\n","- *state*\n","- *state_abbreviation*\n","- *county*\n","- *fips* county identifier\n","- *party*\n","- *candidate*\n","- *votes* votes the candidate got in the county\n","- *fraction_votes* percentage of the total county votes the candidate got"]},{"cell_type":"markdown","metadata":{"id":"uuSGLGi86h16"},"source":["For each problem - think about how you would work this out first. Talk yourself through each step (or even jot it down) and then code it."]},{"cell_type":"markdown","metadata":{"id":"LlRlt0ip6h16"},"source":["### <font color='#eb3483'> Exercise 1 </font>\n","Overall, which percentage of votes did every party get?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4sKe1M-46h16"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"fWlOfgEK6h16"},"source":["### <font color='#eb3483'> Exercise 2 </font>\n","\n","Who is the democrat candidate that got the most votes in manhattan? and in the state of New York?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4u37v-mI6h16"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"h3T49fXd6h16"},"source":["### <font color='#eb3483'> Exercise 3 </font>\n","How many votes did Donald Trump receive in Texas?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jH812p9v6h16"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"12sxJ93G6h16"},"source":["### <font color='#eb3483'> Exercise 4 </font>\n","\n","Let's consider democrat states those where the democrats got more votes and republican states those where the republican candidates got more votes. Which states are democrat and which republican?\n","\n","\n","*hint: one way to find out is by doing a pivot table using the sum as an aggregating function*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZOuG1SK6h16"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"C9-qTqGn6h16"},"source":["### <font color='#eb3483'> Exercise 5 </font>\n","\n","In how many of the republican states was Donald Trump the most voted republican candidate?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-G1gohw6h16"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}