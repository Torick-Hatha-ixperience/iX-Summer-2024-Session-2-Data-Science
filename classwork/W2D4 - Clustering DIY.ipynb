{"cells":[{"cell_type":"markdown","metadata":{"id":"ZpFQpou6l3Va"},"source":["# <font color='#eb3483'>$K$-Means Clustering</font>\n","\n","In this notebook, we are going to apply clustering algorithm to identify homogenous groups of customers from the `mall_customer.csv` dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9AOswsVl3Vd"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"9fcCBQxPl3Vd"},"source":["### <font color='#eb3483'>Import and Explore the Data</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaFLKO3Cl3Ve"},"outputs":[],"source":["#Import your data"]},{"cell_type":"markdown","metadata":{"id":"SO9_2MFDl3Ve"},"source":["<font color='#eb3483'> Explore your data. How large is it? Are there any missing values? What are the data types?"]},{"cell_type":"markdown","metadata":{"id":"w5VY7fXml3Vf"},"source":["<font color='#eb3483'> The income and spending score columns have pretty awkward names. Rename them as \"AnnualIncome\" and \"SpendingScore\", respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m9Y43SgVl3Vf"},"outputs":[],"source":["# rename the columns\n","df.rename(columns={\"Annual Income (k$)\": \"AnnualIncome\", \"Spending Score (1-100)\": \"SpendingScore\"}, inplace=True)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"35CRkSvHl3Vf"},"source":["<font color='#eb3483'>Visualize the `Age` and `SpendingScore` distinguished by `Gender`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJOTe_iMl3Vg"},"outputs":[],"source":["sns.relplot(x=\"Age\", y=\"SpendingScore\", data=df, hue=\"Gender\")"]},{"cell_type":"markdown","metadata":{"id":"P0KgaC18l3Vg"},"source":["### <font color='#eb3483'> Apply $K$-Means Clustering </font>\n","\n","Let's attempt to identify clusters based on Age and SpendingScore. Using two variables will allow us to visualize the results, but feel free to re-run this with all the continuous variables. K-means clustering is not suitable for categorical variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TcteKVa2l3Vg"},"outputs":[],"source":["from sklearn.cluster import KMeans"]},{"cell_type":"markdown","metadata":{"id":"9MT1rVDSl3Vh"},"source":["<font color='#eb3483'>Have a look at the help for `KMeans`. What do the \"init\" and \"n_init\" arguments do?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRwC8E6Nl3Vh"},"outputs":[],"source":["?KMeans"]},{"cell_type":"markdown","metadata":{"id":"qsaFUxYnl3Vh"},"source":["Let's perform K-means clustering with K=4 (no particular reason, just as an example!)..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tjxi9rKxl3Vh"},"outputs":[],"source":["km = KMeans(n_clusters=4) # K = 4\n","km.fit(df[['Age','SpendingScore']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qR4BLs95l3Vi"},"outputs":[],"source":["# Create a DataFrame from the cluster centers of a KMeans model\n","# km.cluster_centers_ contains the centroids of each cluster\n","\n","pd.DataFrame(km.cluster_centers_, columns=['Age','SpendingScore'], index=['Cluster1', 'Cluster2', 'Cluster3', 'Cluster4'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMK5rkhHl3Vi"},"outputs":[],"source":["# Add a new column 'Cluster' to the DataFrame df\n","# km.labels_ contains the cluster labels assigned by KMeans (starting from 0)\n","\n","df['Cluster'] = km.labels_ + 1\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QyqrQF67l3Vi"},"outputs":[],"source":["sns.relplot(x=\"Age\", y=\"SpendingScore\", data=df, hue=\"Cluster\")"]},{"cell_type":"markdown","metadata":{"id":"LNQy2pk0l3Vi"},"source":["### <font color='#eb3483'> Finding the Best $K$ </font>\n","\n","The `sklearn` `KMeans` method calls the total within-cluster variation \"inertia\". This is stored as the `inertia_` attribute of the fitted object. Next, we will loop over different values of $K$, store the inertia and choose the best value of $K$ using the \"elbow\" method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LzvvWTdl3Vi"},"outputs":[],"source":["inertia = []\n","for k in range(1, 11):\n","    kmeans = KMeans(n_clusters=k, random_state=0)\n","    kmeans.fit(df[['Age','SpendingScore']])\n","    inertia.append(kmeans.inertia_)\n","\n","# Plotting the inertia values\n","plt.figure(figsize=(10, 6))\n","plt.plot(range(1, 11), inertia, marker='o')\n","plt.xlabel('Number of clusters (k)')\n","plt.ylabel('Inertia')\n","plt.title('Inertia vs. Number of clusters')\n","plt.xticks(np.arange(1, 11, 1))  # Set x-axis ticks to integers\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UurLNlOAl3Vj"},"source":["<font color='#eb3483'>Exercise: </font> How many clusters would you select? (There is no single \"right\" answer.)"]},{"cell_type":"markdown","metadata":{"id":"ORxkbrSAl3Vj"},"source":["# <font color='#eb3483'> Hierarchical Clustering </font>\n","\n","Let's try hierarchical clustering instead..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fiOzZOn8l3Vj"},"outputs":[],"source":["from sklearn.cluster import AgglomerativeClustering\n","#?AgglomerativeClustering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWsLcyiVl3Vk"},"outputs":[],"source":["from scipy.cluster.hierarchy import dendrogram, linkage\n","import matplotlib.pyplot as plt\n","\n","# Perform hierarchical clustering\n","Z = linkage(df[['Age', 'SpendingScore']])\n","\n","# Plot the dendrogram\n","plt.figure(figsize=(12, 6))\n","dendrogram(Z)\n","plt.xlabel('Sample Index')\n","plt.ylabel('Distance')\n","plt.title('Hierarchical Clustering Dendrogram')\n","plt.show()"]},{"cell_type":"markdown","source":["Lets apply 3 clusters"],"metadata":{"id":"tl5UoEmFoy0j"}},{"cell_type":"code","source":["# Perform agglomerative clustering\n","hier = AgglomerativeClustering(n_clusters=3, linkage='ward')\n","hier.fit(df[['Age', 'SpendingScore']])"],"metadata":{"id":"35bNdG15ol95"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cakBpJnal3Vl"},"outputs":[],"source":["df['Cluster'] = hier.labels_ + 1\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3iJn2U8l3Vl"},"outputs":[],"source":["sns.relplot(x=\"Age\", y=\"SpendingScore\", data=df, hue=\"Cluster\")"]},{"cell_type":"markdown","source":["## Evaluating clustering\n","\n","* Silhouette Score: The silhouette score measures how similar an object is to its own cluster compared to other clusters. It ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\n","\n","* Davies-Bouldin Index: This index measures the average similarity between each cluster and its most similar cluster, taking into account the cluster's size. It ranges from 0 to infinity, with lower values indicating better clustering.\n","\n","* Calinski-Harabasz Index (Variance Ratio Criterion): This index compares the ratio of the variance within clusters with the variance between clusters. A higher value indicates better clustering.\n","* Visual Inspection: Sometimes, simply visualizing the clusters can provide insight into the quality of clustering. Scatter plots, heatmaps, and other visualization techniques can help assess how well the data points are grouped.\n","\n","* Domain Knowledge: In many cases, domain knowledge is essential for evaluating clustering results. Subject matter experts can assess whether the clusters make sense in the context of the data and the problem domain."],"metadata":{"id":"Ot6DdnnxpLjK"}},{"cell_type":"code","source":["from sklearn.metrics import silhouette_score\n","\n","# Assuming labels are the cluster labels obtained from AgglomerativeClustering\n","\n","hier = AgglomerativeClustering(n_clusters=3, linkage='ward')\n","labels = hier.fit_predict(df[['Age', 'SpendingScore']])\n","\n","silhouette_avg = silhouette_score(df[['Age', 'SpendingScore']], labels)\n","print(f\"Silhouette Score: {silhouette_avg}\")"],"metadata":{"id":"wfWZ_sKxpcYE"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
