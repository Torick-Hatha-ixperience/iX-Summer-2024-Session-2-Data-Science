{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO2VgiJqbhDg"
      },
      "source": [
        "# <font color='#eb3483'>Ensemble Methods</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogp9Pi0rbhDh"
      },
      "source": [
        "Ensemble methods combine several several machine learning models (a.k.a. base learners) in order to produce one optimal predictive model. In this lession we study different types of ensemble methods. Before we begin, let's load the necessary libraries and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pZbpp4DbhDi"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCfUAP8AbhDi"
      },
      "source": [
        "### <font color='#eb3483'>Load data</font>\n",
        "\n",
        "The California housing dataset contains information on various socio-economic features of block groups in California. Each row in the dataset represents a single block group, and there are 20,640 observations, each with 10 attributes.\n",
        "\n",
        "Features are as follows:\n",
        "1. Longitude: The longitude of the center of each block group in California.\n",
        "2.Latitude: The latitude of the center of each block group in California.\n",
        "3.Housing Median Age: The median age of the housing units in each block group.\n",
        "4.Total Rooms: The total number of rooms in the housing units in each block group.\n",
        "5.Total Bedrooms: The total number of bedrooms in the housing units in each block group.\n",
        "6.Population: The total population of the block group.\n",
        "7.Households: The total number of households in the block group.\n",
        "8.Median Income: The median income of the block group.\n",
        "9.Median House Value: The median value of the housing units in the block group.\n",
        "10.Ocean Proximity: The proximity of the block group to the ocean or other bodies of water."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaeJjZ_ybhDi"
      },
      "outputs": [],
      "source": [
        "#Import from Data Folder in Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Data Science | Abroad | S1 | Claire/Class Materials/Week 3-6 Special Topics/W3D1 Tree Ensembles/Classwork/housing.csv\"\n",
        "data = pd.read_csv(path)\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "metadata": {
        "id": "EeAY0X1NdwZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_vq4Ma9bhDj"
      },
      "outputs": [],
      "source": [
        "# See head of the dataset\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#eb3483'>EDA</font>"
      ],
      "metadata": {
        "id": "k_cU-swKgaw2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4ERZbvzbhDj"
      },
      "outputs": [],
      "source": [
        "#Check the shape of dataframe\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LaepWW3bhDj"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV9OrHDHbhDj"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhGog13vbhDj"
      },
      "outputs": [],
      "source": [
        "# Identifying the unique number of values in the dataset\n",
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3QAVxD7bhDj"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tn0o6HXbhDj"
      },
      "outputs": [],
      "source": [
        "# See rows with missing values\n",
        "data[data.isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"ocean_proximity\"].value_counts(ascending=True)"
      ],
      "metadata": {
        "id": "UztMiSjezpdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Categorical Variable ('ocean_proximity')\n",
        "plt.figure(figsize=(8, 3))\n",
        "sns.countplot(x=data['ocean_proximity'])\n",
        "plt.title('Distribution of Ocean Proximity')\n",
        "plt.xlabel('Ocean Proximity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kyn_Ku2jf7_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0HqzVR_bhDj"
      },
      "outputs": [],
      "source": [
        "# Finding out the correlation between the features\n",
        "# Exclude non-numeric columns for correlation heatmap\n",
        "numeric_data = data.drop(columns=['ocean_proximity'])\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "corr = numeric_data.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_correlation= corr\n",
        "\n",
        "for feature, correlation in price_correlation.items():\n",
        "        if correlation.any() > 0:\n",
        "            print(f\"There is a positive correlation between house price and {feature}\")\n",
        "        elif correlation < 0:\n",
        "            print(f\"There is a negative correlation between house price and {feature}\")\n",
        "        else:\n",
        "            print(f\"There is no correlation between house price and {feature}\")"
      ],
      "metadata": {
        "id": "sXtIqXOmlBYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of latitude and longitude to visualize geographical data\n",
        "plt.figure(figsize=(5, 3))\n",
        "sns.scatterplot(x='longitude', y='latitude', data=data, hue='median_house_value', palette='coolwarm', alpha=0.6)\n",
        "plt.title('Geographical Distribution of Housing Prices')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cPtCzp7dfkQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of Target Variable ('median_house_value')\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.histplot(data['median_house_value'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of House Prices')\n",
        "plt.xlabel('Median House Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s8KkRgTYfqxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(data[\"median_income\"],data[\"median_house_value\"],alpha=0.3)\n",
        "plt.title=(\"median_income vs median_house_value\")\n",
        "plt.xlabel(\"median_income\")\n",
        "plt.ylabel(\"median_house_value\")"
      ],
      "metadata": {
        "id": "QEva355B0dw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot of median house value\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='ocean_proximity', y='median_house_value',data=data)\n",
        "plt.title('Median House Value by Ocean Proximity')\n",
        "plt.xlabel('Ocean Proximity')\n",
        "plt.ylabel('Median House Value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "stHOKGADv-bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z33AQEpbhDj"
      },
      "outputs": [],
      "source": [
        "#Outlier detection\n",
        "#Lets check if there are any outliers in our dataset\n",
        "print(data.median_house_value.value_counts().head())\n",
        "california = data[data.median_house_value != 50.0]\n",
        "california.plot(kind='box', rot=90, logy=True,figsize=(20,10));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBZpQH5JbhDk"
      },
      "source": [
        "We see that different features are on different scales our linear models(regularized ones) would need to have the data scaled. There are a lot of outliers in the dataset in majority of the features. We will first see how each predictor models the response."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#eb3483'>Feature Engineering</font>"
      ],
      "metadata": {
        "id": "JBJUMkIAj2t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new feature 'rooms_per_household', which represents the average number of rooms per household\n",
        "data['rooms_per_household'] = data['total_rooms'] / data['households']\n",
        "data.head(2)"
      ],
      "metadata": {
        "id": "zMoUdWrigLtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['ocean_proximity_encoded'] = label_encoder.fit_transform(data['ocean_proximity'])"
      ],
      "metadata": {
        "id": "gzfBR6H3l1G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weqRygrJbhDk"
      },
      "outputs": [],
      "source": [
        "# Splitting to training and testing data\n",
        "X=data[['longitude','latitude','housing_median_age','rooms_per_household','population','households','median_income','ocean_proximity_encoded']]\n",
        "y = data['median_house_value']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liW6m8KkbhDk"
      },
      "source": [
        "We will train some models to get a good baseline of what performance should be"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_0_52ijbhDk"
      },
      "source": [
        "## 1. Linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc-lZrTUbhDk"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU0OIGJMbhDk"
      },
      "outputs": [],
      "source": [
        "# Import library for Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a Linear regressor\n",
        "lm = LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "lm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB-6HvCIbhDk"
      },
      "outputs": [],
      "source": [
        "# Value of y intercept\n",
        "lm.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xbYzSj3bhDk"
      },
      "outputs": [],
      "source": [
        "#Converting the coefficient values to a dataframe\n",
        "coeffcients = pd.DataFrame([X_train.columns,lm.coef_]).T\n",
        "coeffcients = coeffcients.rename(columns={0: 'Attribute', 1: 'Coefficients'})\n",
        "coeffcients"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remeber:**\n",
        "\n",
        "* The magnitude of the coefficient indicates the strength of the relationship. A larger magnitude suggests a stronger impact on the target variable.\n",
        "\n",
        "* The sign of the coefficient (+ or -) indicates the direction of the relationship. A positive coefficient means that as the feature increases, the target variable is expected to increase as well. A negative coefficient means that as the feature increases, the target variable is expected to decrease."
      ],
      "metadata": {
        "id": "8cvUOcG1taJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importance from the coefficients\n",
        "feature_importance = pd.Series(lm.coef_, index=X.columns)\n",
        "feature_importance = feature_importance.abs().sort_values(ascending=False)\n",
        "\n",
        "# Plotting the feature importances\n",
        "plt.figure(figsize=(12, 6))\n",
        "feature_importance.plot(kind='barh')\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis to flip the bars\n",
        "plt.title('Feature Importance in Linear Regression')\n",
        "plt.xlabel('Coefficient Magnitude')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6cqyJnPmiP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgR9LAAVbhDk"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iwJPxaabhDk"
      },
      "outputs": [],
      "source": [
        "# Model prediction on train data\n",
        "y_pred = lm.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC0MgPezbhDk"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "print('R^2:',metrics.r2_score(y_train, y_pred))\n",
        "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\n",
        "print('MAE:',metrics.mean_absolute_error(y_train, y_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_train, y_pred))\n",
        "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AMJZtfrbhDk"
      },
      "source": [
        "ùëÖ^2 : It is a measure of the linear relationship between X and Y. It is interpreted as the proportion of the variance in the dependent variable that is predictable from the independent variable.\n",
        "\n",
        "Adjusted ùëÖ^2 :The adjusted R-squared compares the explanatory power of regression models that contain different numbers of predictors.\n",
        "\n",
        "MAE : It is the mean of the absolute value of the errors. It measures the difference between two continuous variables, here actual and predicted values of y.\n",
        "\n",
        "MSE: The mean square error (MSE) is just like the MAE, but squares the difference before summing them all instead of using the absolute value.\n",
        "\n",
        "RMSE: The mean square error (MSE) is just like the MAE, but squares the difference before summing them all instead of using the absolute value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9zSgJKabhDk"
      },
      "outputs": [],
      "source": [
        "# Visualizing the differences between actual prices and predicted values\n",
        "plt.scatter(y_train, y_pred,alpha=0.3)\n",
        "plt.xlabel(\"Prices\")\n",
        "plt.ylabel(\"Predicted prices\")\n",
        "plt.title(\"Prices vs Predicted prices\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01Xi6DBbhDl"
      },
      "source": [
        "### For test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCfDY1EqbhDl"
      },
      "outputs": [],
      "source": [
        "# Predicting Test data with the model\n",
        "y_test_pred = lm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-X_-WeDbhDl"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "acc_linreg = metrics.r2_score(y_test, y_test_pred)\n",
        "print('R^2:', acc_linreg)\n",
        "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\n",
        "print('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\n",
        "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es-eqsYibhDl"
      },
      "source": [
        "Here the model evaluations scores are almost matching with that of train data. So the model is not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IsJUszsbhDl"
      },
      "source": [
        "## 2. Random Forest Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUM-J3DvbhDm"
      },
      "source": [
        "### Train the model: X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpJorK41bhDm"
      },
      "outputs": [],
      "source": [
        "# Import Random Forest Regressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create a Random Forest Regressor\n",
        "reg = RandomForestRegressor()\n",
        "\n",
        "# Train the model using the training sets\n",
        "reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYQjD7iqbhDm"
      },
      "outputs": [],
      "source": [
        "RandomForestRegressor?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tYub5E6bhDm"
      },
      "source": [
        "sklearn's RandomForest implementation trains each base tree with a dataset the same size as the training dataset (sampling with replacement if `bootstrap=True`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hePuIPi9bhDm"
      },
      "outputs": [],
      "source": [
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
        "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je9fA5fzbhDm"
      },
      "outputs": [],
      "source": [
        "# if we make n_estimators higher than 100 it would take looonger to run. #stop kernel\n",
        "# try a few options and see the performance of the model e.g. randomforest_10 versus randomforest_100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9JvsfRwbhDm"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQEOQ7VWbhDm"
      },
      "outputs": [],
      "source": [
        "# Model prediction on train data\n",
        "y_pred = reg.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fulPp_5_bhDm"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "acc_rf_train = metrics.r2_score(y_train, y_pred)\n",
        "print('R^2:',metrics.r2_score(y_train, y_pred))\n",
        "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\n",
        "print('MAE:',metrics.mean_absolute_error(y_train, y_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_train, y_pred))\n",
        "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Root Mean Squared Error (RMSE) of approximately 18688 indicates that, on average, the model's predictions deviate by around $18688 from the actual house prices in the test set. This value gives us an understanding of the performance of the model in predicting house prices, with lower RMSE values indicating better performance."
      ],
      "metadata": {
        "id": "6XtTAcDauMvO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCeMu84CbhDm"
      },
      "outputs": [],
      "source": [
        "# Visualizing the differences between actual prices and predicted values\n",
        "plt.scatter(y_train, y_pred,alpha=0.3)\n",
        "plt.xlabel(\"Prices\")\n",
        "plt.ylabel(\"Predicted prices\")\n",
        "plt.title(\"Prices vs Predicted prices\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcaKbOmdbhDm"
      },
      "source": [
        "### For test data: : X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uu0uu9gbhDm"
      },
      "outputs": [],
      "source": [
        "# Predicting Test data with the model\n",
        "y_test_pred = reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjFJjSxdbhDm"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "acc_rf = metrics.r2_score(y_test, y_test_pred)\n",
        "print('R^2:', acc_rf)\n",
        "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\n",
        "print('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\n",
        "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUCb4ZTlbhDn"
      },
      "source": [
        "Another example of \"extremely randomised Trees\"\n",
        "There is a different kind of decision tree type named Extremely Randomized Trees that decide the tree splits into branches completely randomly (ie not based on information gain).\n",
        "\n",
        "These trees are weak estimators by themselves (not surprisingly).\n",
        "\n",
        "However, they are better than a 100% random estimator, and each random tree is different. This makes then a perfect estimator a perfect base estimator, because by aggregating a group of them the general error diminishes. Since each tree is trained on a different set of observations, their errors will differ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMZ8w9wbhDn"
      },
      "source": [
        "## 3. XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLbepouobhDn"
      },
      "source": [
        "XGBoost (eXtreme Gradient Boosting) implements gradient boosted trees but focused on large datasets.\n",
        "\n",
        "Because it is a relatively new dataset (the research started in 2014, and the original paper was published in 2016 [link to the](https://arxiv.org/abs/1603.02754)) it is not implemented in scikit-learn. However it is avaiable in the package [xgboost](http://xgboost.readthedocs.io/en/latest/python/python_intro.html), that implements XGBoost that follow's scikit-learn api."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7QhzlLNbhDn"
      },
      "outputs": [],
      "source": [
        "# Import XGBoost Regressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#Create a XGBoost Regressor\n",
        "reg = XGBRegressor()\n",
        "\n",
        "# Train the model using the training sets\n",
        "reg.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFlf9SMObhDn"
      },
      "outputs": [],
      "source": [
        "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
        "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
        "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
        "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "       silent=True, subsample=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UXLIB31bhDn"
      },
      "outputs": [],
      "source": [
        "# here we change a number of parameters e.g. made n_estimators=100\n",
        "#XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "#       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
        "#       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
        "#       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "#       silent=True, subsample=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdwiX0T8bhDn"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahkwV9n5bhDn"
      },
      "outputs": [],
      "source": [
        "# Model prediction on train data\n",
        "y_pred = reg.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXwJ1RxzbhDn"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "print('R^2:',metrics.r2_score(y_train, y_pred))\n",
        "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\n",
        "print('MAE:',metrics.mean_absolute_error(y_train, y_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_train, y_pred))\n",
        "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2VTNCM_bhDn"
      },
      "outputs": [],
      "source": [
        "# Visualizing the differences between actual prices and predicted values\n",
        "plt.scatter(y_train, y_pred,alpha=0.3)\n",
        "plt.xlabel(\"Prices\")\n",
        "plt.ylabel(\"Predicted prices\")\n",
        "plt.title(\"Prices vs Predicted prices\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esu7N7_obhDn"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUS-WjMcbhDn"
      },
      "outputs": [],
      "source": [
        "#Predicting Test data with the model\n",
        "y_test_pred = reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rCVSat8bhDo"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "acc_xgb = metrics.r2_score(y_test, y_test_pred)\n",
        "print('R^2:', acc_xgb)\n",
        "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\n",
        "print('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\n",
        "print('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\n",
        "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kCOyCbtbhDo"
      },
      "source": [
        "# Evaluation and comparision of all the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fZ8wgIbbhDo"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
        "    'R-squared Score': [acc_linreg*100, acc_rf*100, acc_xgb*100]})\n",
        "models.sort_values(by='R-squared Score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFZ-QpdVbhDo"
      },
      "outputs": [],
      "source": [
        "#add test and train outputs to the table as well\n",
        "#acc_rf_train*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxYF_twabhDo"
      },
      "source": [
        "Which one works the best for this dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7LuILDwbhDo"
      },
      "source": [
        "BONUS: try out and compare SVM Regressor or any other algorithm of interest\n",
        "Here is a useful article if you want to read up a bit more on boosting https://www.analyticsvidhya.com/blog/2020/02/4-boosting-algorithms-machine-learning/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}