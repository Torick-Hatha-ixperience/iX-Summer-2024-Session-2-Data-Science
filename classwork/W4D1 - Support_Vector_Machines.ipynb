{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go1Lz6UWt8bR"
      },
      "source": [
        "# <font color='#eb3483'> Support Vector Machines (SVM) </font>\n",
        "\n",
        "Support vector machines were all the rage ten years ago and still remain an awesome machine learning algorithm.\n",
        "\n",
        "SVMs work by trying to find a hyperplane (a fancy high-dimensional verson of a line/plane) in N-dimensional space (where N is the number of features) that separates your data-points into different classes.\n",
        "\n",
        "In this module we'll walk through how to train a SVM using scikit-learn and visualize it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnljRsLUt8bS"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCcGMXk6t8bT"
      },
      "source": [
        "### <font color='#eb3483'> Breast Cancer Wisconsin Dataset </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb4j2f2Kt8bT"
      },
      "outputs": [],
      "source": [
        "# Load the Breast Cancer Wisconsin dataset\n",
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "GQllvsy2t8bU"
      },
      "outputs": [],
      "source": [
        "print(breast_cancer.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WreYVR5Kt8bU"
      },
      "outputs": [],
      "source": [
        "breast_cancer.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT2O4MuFt8bU"
      },
      "source": [
        "### <font color='#eb3483'> Training a SVM </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL3wqKa-t8bV"
      },
      "source": [
        "SVM models in `scikit-learn` are in the module `sklearn.svm`.   \n",
        "\n",
        "SVM is another algorithm that can be used both for regression (continuous variables) and classification (categories).  \n",
        "\n",
        "There is an implementation for regression (`SVR`) and another one for classification (`SVC`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DKyjH6ht8bV"
      },
      "outputs": [],
      "source": [
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create an SVM classifier with a linear kernel\n",
        "svm = SVC()\n",
        "\n",
        "# Train the model\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm.predict(X_test)\n",
        "y_pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Detailed classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "XD3Tvhkdvk99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie4Oi84vt8bV"
      },
      "source": [
        "Here are some parameters you might find helpful:\n",
        "- **C** is the Cost parameter (that regulates the slack variables that help regularize the model).\n",
        "- **kernel** specifies the kernel (rbf, (radial basis function) by default). We can use any kernel we define or any of the available ones (`rbf`, `poly` (polynomial), `linear`or `sigmoid`).\n",
        "- **class_weight**, allows us to use a dictionary `{clase:peso}` that allows us to assign custom weights to classes. For imbalanced classification problems we can use `class_weight=balanced` that automatically balances the classes based on their support.\n",
        "- **decision_function_shape** Choose if using One-versus-one (ovo) or One-versus-rest (ovr) for multiclass classification.\n",
        "- **probability**. If we want to calculate the class probabilities (and use `predict_proba`) (False by default).\n",
        "- **cache_size** is the size in (megabytes) the model can use to store calculation data in memory. SVMs are computationally intensive, so the bigger the cache the better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rcCwCo9t8bV"
      },
      "source": [
        "## <font color='#eb3483'>  Kernels </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4H5grgmt8bV"
      },
      "source": [
        "Let's see  the effect of different kernels (i.e. ways to measure distance between points) on the decision hyperplane.\n",
        "\n",
        "We will use only the first 2 dataset variables to be able to plot them on a scatter plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm7YyCzot8bV"
      },
      "outputs": [],
      "source": [
        "X = breast_cancer.data[:, :2]\n",
        "y = breast_cancer.target\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyrlFNcXt8bV"
      },
      "source": [
        "We are going to use a utility function in, `plot_decision_regions` that plots a diagram indicating the different decision regions for each class. You will need to install Mlxtend (machine learning extensions), a Python library of useful tools for the day-to-day data science tasks. `conda install mlxtend --channel conda-forge`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VzJi-mut8bV"
      },
      "outputs": [],
      "source": [
        "from mlxtend.plotting import plot_decision_regions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtHIFrxLt8bV"
      },
      "source": [
        "**Linear Kernel**\n",
        "This kernel is simple and works well when the data is linearly separable.\n",
        "\n",
        "The linear kernel is defined as:\n",
        "\n",
        "$$\\text{Linear Kernel}: k(x,y) = x^Ty+c$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATf0h1Ikt8bV"
      },
      "outputs": [],
      "source": [
        "estimator_svm_lineal = SVC(kernel=\"linear\")\n",
        "estimator_svm_lineal.fit(X, y)\n",
        "\n",
        "plot_decision_regions(X, y, clf=estimator_svm_lineal);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLmWuscFt8bV"
      },
      "source": [
        "**Polynomial Kernel**\n",
        "\n",
        "The polynomial kernel calculates the product of two vectors in a dimensional space of the polynomial combinations of the vectors. So if we have 2 vectors $V_1$ and $V_2$ shaped $[x_1, x_2]$, the polynomial kernel is going to transform them into $[x_1, x_2, x_1^2, x_1x_2, x_2^2...]$ . It has the formula:\n",
        "\n",
        "$$\\text{polynomial kernel}: k(x,y) = (\\alpha x^Ty+c)^p$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O0TDYy-t8bV"
      },
      "source": [
        "The polynomial kernel has a hyperparameter `d` (degree) that indicates the degree of the polynomial expansion (3 by default)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSE74A6et8bV"
      },
      "outputs": [],
      "source": [
        "estimator_svm_polinomial = SVC(kernel=\"poly\")\n",
        "estimator_svm_polinomial.fit(X, y)\n",
        "\n",
        "plot_decision_regions(X, y, clf=estimator_svm_polinomial);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqnHlg99t8bW"
      },
      "source": [
        "We see that the decision boundary became a polynomial line (curved line). The more degrees of the expansion the more \"curved\" the lines can be. If we use a polynomial kernel with `degree=1` we get a linear kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42ZxLwQtt8bW"
      },
      "outputs": [],
      "source": [
        "estimator_svm_polinomial_1 = SVC(kernel=\"poly\", degree=1).fit(X, y)\n",
        "plot_decision_regions(X, y, clf=estimator_svm_polinomial_1);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7gSSSeWt8bW"
      },
      "outputs": [],
      "source": [
        "estimator_svm_polinomial_2 = SVC(kernel=\"poly\", degree=2).fit(X, y)\n",
        "plot_decision_regions(X, y, clf=estimator_svm_polinomial_2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coXEsSfIt8bW"
      },
      "outputs": [],
      "source": [
        "estimator_svm_polinomial_3 = SVC(kernel=\"poly\", degree=3, gamma=0.1).fit(X, y)\n",
        "plot_decision_regions(X, y, clf=estimator_svm_polinomial_3);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVVDDbvSt8bW"
      },
      "source": [
        "A low `d` reduces the complexity of the polynomial kernel (turning it into a linear kernel)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yiSAz6Zt8bW"
      },
      "source": [
        "The **Radial Basis Function**\n",
        "\n",
        "This kernel can map the data to a higher-dimensional space and is effective for non-linearly separable data.\n",
        "\n",
        "(RBF) kernel does a radial transformation (that is, transforms the points based to their distance to the origin). It has the formulation:\n",
        "\n",
        "$$\\text{radial kernel}: k(x,y) = \\exp(-\\gamma ||x - y^2||))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NqWXjyet8bW"
      },
      "outputs": [],
      "source": [
        "estimator_svm_rbf = SVC(kernel=\"rbf\")\n",
        "estimator_svm_rbf.fit(X, y)\n",
        "\n",
        "plot_decision_regions(X, y, clf=estimator_svm_rbf);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqeos-Srt8bW"
      },
      "source": [
        "We can control the shape of the decision boundary with the hyperparameter `gamma`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3A37H8Dt8bW"
      },
      "outputs": [],
      "source": [
        "estimator_svm_rbf_a = SVC(kernel=\"rbf\", gamma=0.1).fit(X, y)\n",
        "plot_decision_regions(X, y, clf=estimator_svm_rbf_a);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTcTvC6jt8bW"
      },
      "outputs": [],
      "source": [
        "estimator_svm_rbf_b = SVC(kernel=\"rbf\", gamma=7).fit(X, y)\n",
        "plot_decision_regions(X, y, clf=estimator_svm_rbf_b);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEWqyZvst8bW"
      },
      "outputs": [],
      "source": [
        "estimator_svm_rbf_c = SVC(kernel=\"rbf\", gamma=100).fit(X, y)\n",
        "plot_decision_regions(X, y, clf=estimator_svm_rbf_c);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTRtZG4Et8bW"
      },
      "source": [
        "Higher `gamma` values increase rbf's kernel capability to create areas around the data.\n",
        "We see that for `gamma=100` the model is overfitting (basically creating tiny circles around each observation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#eb3483'>  Evaluate SVM with different kernels </font>"
      ],
      "metadata": {
        "id": "F73oPlWyyPp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Breast Cancer Wisconsin dataset\n",
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Function to train and evaluate SVM with different kernels\n",
        "def evaluate_svm(kernel_type, **kwargs):\n",
        "    # Create an SVM classifier with the specified kernel\n",
        "    svm = SVC(kernel=kernel_type, **kwargs)\n",
        "\n",
        "    # Train the model\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = svm.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'Kernel: {kernel_type}')\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Evaluate SVM with different kernels\n",
        "evaluate_svm('linear')\n",
        "evaluate_svm('poly', degree=3)\n",
        "evaluate_svm('rbf', gamma=0.1)"
      ],
      "metadata": {
        "id": "nkS_kOInyNj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}