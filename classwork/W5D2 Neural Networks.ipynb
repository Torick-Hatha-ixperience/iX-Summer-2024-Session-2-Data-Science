{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cropland-Mapping-with-Random-Forests-and-Neural-Networks\" data-toc-modified-id=\"Cropland-Mapping-with-Random-Forests-and-Neural-Networks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cropland Mapping with Random Forests and Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"1.-Introduction-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1. Introduction</a></span></li><li><span><a href=\"#2.-Objectives-of-this-machine-learning-exercise\" data-toc-modified-id=\"2.-Objectives-of-this-machine-learning-exercise-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>2. Objectives of this machine learning exercise</a></span></li><li><span><a href=\"#3.-The-dataset\" data-toc-modified-id=\"3.-The-dataset-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>3. The dataset</a></span></li><li><span><a href=\"#Creating-New-Environment-may-be-needed\" data-toc-modified-id=\"Creating-New-Environment-may-be-needed-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Creating New Environment may be needed</a></span></li><li><span><a href=\"#4.1.-Importing-required-libraries\" data-toc-modified-id=\"4.1.-Importing-required-libraries-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>4.1. Importing required libraries</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.3.-Importing-the-dataset\" data-toc-modified-id=\"4.3.-Importing-the-dataset-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>4.3. Importing the dataset</a></span></li></ul></li><li><span><a href=\"#5.-Exploratory-data-analysis-and-preprocessing\" data-toc-modified-id=\"5.-Exploratory-data-analysis-and-preprocessing-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>5. Exploratory data analysis and preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1.-Correlation\" data-toc-modified-id=\"5.1.-Correlation-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>5.1. Correlation</a></span></li><li><span><a href=\"#5.3.-Creating-train-and-test-sets\" data-toc-modified-id=\"5.3.-Creating-train-and-test-sets-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>5.3. Creating train and test sets</a></span></li><li><span><a href=\"#5.4.-Feature-scaling\" data-toc-modified-id=\"5.4.-Feature-scaling-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span>5.4. Feature scaling</a></span></li></ul></li><li><span><a href=\"#6.-Machine-Learning\" data-toc-modified-id=\"6.-Machine-Learning-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>6. Machine Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.2.-Deep-Learning-(Artificial-Neural-Network)\" data-toc-modified-id=\"6.2.-Deep-Learning-(Artificial-Neural-Network)-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>6.2. Deep Learning (Artificial Neural Network)</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.2.1.-Model-definition\" data-toc-modified-id=\"6.2.1.-Model-definition-1.7.1.1\"><span class=\"toc-item-num\">1.7.1.1&nbsp;&nbsp;</span>6.2.1. Model definition</a></span></li><li><span><a href=\"#6.2.2.-Model-fitting\" data-toc-modified-id=\"6.2.2.-Model-fitting-1.7.1.2\"><span class=\"toc-item-num\">1.7.1.2&nbsp;&nbsp;</span>6.2.2. Model fitting</a></span></li><li><span><a href=\"#6.2.3.-Predictions\" data-toc-modified-id=\"6.2.3.-Predictions-1.7.1.3\"><span class=\"toc-item-num\">1.7.1.3&nbsp;&nbsp;</span>6.2.3. Predictions</a></span></li></ul></li></ul></li><li><span><a href=\"#7.-Classification-performance\" data-toc-modified-id=\"7.-Classification-performance-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>7. Classification performance</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HoaY5cLXXva"
   },
   "source": [
    "# Cropland Mapping with Random Forests and Neural Networks\n",
    "\n",
    "<p style=\"text-align: justify\">This case study is based on the \"<b>Crop mapping using fused optical-radar dataset</b>\", created by <a href=\"http://i-khosravi.ir/\">Dr. Iman Khosravi</a> (Department of Remote Sensing & GIS, Faculty of Geography, University of Tehran, Iran) and donated to the <b>University of California, Irvine (UCI) Machine Learning Repository</b> (<a href=\"https://archive.ics.uci.edu/ml/datasets/Crop+mapping+using+fused+optical-radar+data+set\">here</a>), where it is currently hosted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaDNa5_uc_Nv"
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQ4_bdmnc_Nv"
   },
   "source": [
    "Crop maps play an important role in various applications such as crop inventories, crop insurance, yield estimation and the enforcement of quota limits.\n",
    "\n",
    "The dataset serving as the basis for this machine learning study, described in detail in Section 3, contains a large set of numerical features derived from remote sensing information assembled by two primary sources:</p>\n",
    "<ul>\n",
    "    <li style=\"text-align: justify\">Optical information (actual images) was collected by RapidEye satellites;</li>\n",
    "    <li style=\"text-align: justify\">Radar-based information was collected by an Unihnabitated Aerial Vehicle Synthetic Aperture Radar (UAVSAR) system.</li>\n",
    "</ul>\n",
    "<p style=\"text-align: justify\">As the amount and complexity of data gathered from such different sources over several time spans is inherently huge, <b>machine learning</b> plays a central role when it comes to the final classification purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unKGD74Qc_Nw"
   },
   "source": [
    "<img src=\"https://i.imgur.com/4oTGmTA.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb5cvzjKc_Nw"
   },
   "source": [
    "## 2. Objectives of this machine learning exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4WSsq5wc_Nx"
   },
   "source": [
    "<p style=\"text-align: justify\">Two major objectives are proposed for this study:</p>\n",
    "<ol>\n",
    "    <li style=\"text-align: justify\">Assess the performance of scikit-learn's Random Forest Classifier;</li>\n",
    "    <li style=\"text-align: justify\">Investigate potential performance improvements that may be offered by an Artificial Neural Network (ANN).</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Cb56fEpc_Nx"
   },
   "source": [
    "## 3. The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4xPzMNcc_Nx"
   },
   "source": [
    "<p style=\"text-align: justify\">The dataset chosen for this machine learning exercise contains fused, bi-temporal optical-radar data for cropland classification, in tabular form, derived from images collected by RapidEye satellites (optical) and polarimetric radar information collected by Unmanned Aerial Vehicle Synthetic Aperture Radars (UAVSAR) over an agricultural region near <b>Winnipeg, Canada</b> on <b>July 5th and July 14th, 2012</b>. In this area, seven different crop cultures existed at the time of collection:</p>\n",
    "<ol>\n",
    "    <li style=\"text-align: justify\">Corn</li>\n",
    "    <li style=\"text-align: justify\">Pea</li>\n",
    "    <li style=\"text-align: justify\">Canola</li>\n",
    "    <li style=\"text-align: justify\">Soy</li>\n",
    "    <li style=\"text-align: justify\">Oat</li>\n",
    "    <li style=\"text-align: justify\">Wheat</li>\n",
    "    <li style=\"text-align: justify\">Broadleaf</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzWnQk2qc_Nx"
   },
   "source": [
    "<img src=\"https://i.imgur.com/KAaR1oa.png\" width=\"800\" height=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFfoeVIPc_Nx"
   },
   "source": [
    "<p style=\"text-align: justify\">The dataset has 325,834 observations, each containing 175 attributes structured the following way:</p>\n",
    "<p><b>Dependent variable</b>:</p>\n",
    "<ul>\n",
    "    <li style=\"text-align: justify\">Crop class, as described above ('label', integer value ranging from 1 to 7);</li>\n",
    "</ul>\n",
    "<p><b>Predictive features</b>:</p>\n",
    "<ul>\n",
    "    <li style=\"text-align: justify\">Polarimetric radar features (49) collected on July 5th, 2012 ('f1' to 'f49', real values);</li>\n",
    "    <li style=\"text-align: justify\">Polarimetric radar features (49) collected on July 14th, 2012 ('f50' to 'f98', real values);</li>\n",
    "    <li style=\"text-align: justify\">Optical features (38) collected on July 5th, 2012 ('f99' to 'f136', real values);</li>\n",
    "    <li style=\"text-align: justify\">Optical features (38) collected on July 14th, 2012 ('f137' to 'f174', real values).</li>\n",
    "</ul>\n",
    "<p style=\"text-align: justify\">There are no missing values.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating New Environment may be needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in terminal line by line\n",
    "# Create and activate a new virtual environment\n",
    "python -m venv myenv\n",
    "source myenv/bin/activate  # On Windows use `myenv\\Scripts\\activate`\n",
    "\n",
    "# Upgrade pip\n",
    "pip install --upgrade pip\n",
    "\n",
    "# Install Jupyter and necessary packages\n",
    "pip install jupyter tensorflow pandas scikit-learn ipykernel\n",
    "\n",
    "# Add the virtual environment to Jupyter\n",
    "python -m ipykernel install --user --name=myenv --display-name \"Python (myenv)\"\n",
    "\n",
    "# Launch Jupyter Notebook\n",
    "jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPMZ7Gd3c_Nx"
   },
   "source": [
    "## 4.1. Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsIIqK0UXSUN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_fscore_support\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9zdp0b5c_Ny"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOygnihzc_Nz"
   },
   "source": [
    "### 4.3. Importing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIoj5F0Fc_Nz"
   },
   "source": [
    "<p style=\"text-align: justify\">The dataset containing 325,834 observations is imported and shuffled.</p> Preventing Order Bias: Datasets often have some inherent order, such as time-series data or grouped data. If this order is preserved, models may learn spurious patterns or relationships that are not generalizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFi2NNY7Xf6c"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('WinnipegDataset.txt')\n",
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ifv88VIBc_Nz"
   },
   "source": [
    "## 5. Exploratory data analysis and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJPMra3fc_Nz"
   },
   "source": [
    "<p style=\"text-align: justify\">A glimpse at the dataset structure confirms observation shuffling.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUz0vXPoc_Nz",
    "outputId": "ac0f8df7-7ba3-4f8f-d1db-ac3e7cd08a33"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylNAAS7Tc_N0"
   },
   "source": [
    "<p style=\"text-align: justify\">In addition, the analysis of unique labels shows a somehow balanced distribution (class share percentages mapped and charted below), with the exception of '<b>broadleaf</b>' and '<b>pea</b>'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Nrd1_xoc_N0",
    "outputId": "04cc09cd-5064-4139-88ed-50a932d2ad23"
   },
   "outputs": [],
   "source": [
    "class_share = pd.Series(100 * dataset.label.value_counts(normalize=True)).sort_index()\n",
    "print('Class share\\n')\n",
    "for i in range(0,7):\n",
    "    print(f'Class {class_share.index[i]}: {class_share.iloc[i]:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wylBZpAgc_N0",
    "outputId": "e51d8c77-d737-4269-d22e-b5197b27881f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "sns.barplot(ax=ax, x = class_share.index, y = class_share, palette='Greens_d')\n",
    "plt.title('Cropland Class Share', fontsize=18)\n",
    "plt.xlabel('Cropland Class', fontsize=14)\n",
    "plt.ylabel('Share (%)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQFVQLPkc_N0"
   },
   "source": [
    "### 5.1. Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB9Ib7_2c_N0"
   },
   "source": [
    "A threshold of 0.95 has been arbitrarily defined for filtering highly intercorrelated features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLednyRxc_N0"
   },
   "outputs": [],
   "source": [
    "correlation_matrix = dataset.corr().abs()\n",
    "upper_matrix = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Identify highly correlated features to drop\n",
    "highly_correlated_features_to_drop = [column for column in upper_matrix.columns if any(upper_matrix[column] > 0.95)]\n",
    "\n",
    "# Drop the highly correlated features from the dataset\n",
    "dataset = dataset.drop(columns=highly_correlated_features_to_drop)\n",
    "\n",
    "print(f'Number of features to drop: {len(highly_correlated_features_to_drop)}')\n",
    "print(f'Features to drop: {highly_correlated_features_to_drop}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2GAfVuvc_N6"
   },
   "source": [
    "### 5.3. Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wu6tmytSNKQ"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:]\n",
    "y = dataset.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSWmlRmSXkrO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(f'Training features shape: {X_train.shape}')\n",
    "print(f'Testing features shape: {X_test.shape}')\n",
    "print(f'Training target shape: {y_train.shape}')\n",
    "print(f'Testing target shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6MZZzrsc_N7"
   },
   "source": [
    "<p style=\"text-align: justify\">In preparation for testing at the end of this exercise, mapping class counts in the set of testing labels is important:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr87wBaWc_N7",
    "outputId": "67cb842c-c3b9-45ed-99e6-2f95cdc3feac"
   },
   "outputs": [],
   "source": [
    "class_count = pd.Series(y_test.label.value_counts()).sort_index()\n",
    "print('Class count - Test labels\\n')\n",
    "for i in range(0,7):\n",
    "    print(f'Class {class_count.index[i]}: {class_count.iloc[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the <b>neural network</b> classification, the label column will be one-hot encoded with the help of Pandas' get_dummies method. Therefore, labels will now consist of arrays with seven binary elements, each of them referring to a specific crop class, allowing for the final class identification based on the array element with the highest predicted value.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ann = pd.get_dummies(y_train.label).values\n",
    "y_test_ann = pd.get_dummies(y_test.label).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcezbVB_c_N7"
   },
   "source": [
    "### 5.4. Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjcMS4IQXscR"
   },
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dSmZYrRc_N7"
   },
   "source": [
    "## 6. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG9v9rbac_N8"
   },
   "source": [
    "<p style=\"text-align: justify\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRyzGkTKc_N8"
   },
   "source": [
    "### 6.2. Deep Learning (Artificial Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1UbZmhtc_N8"
   },
   "source": [
    "#### 6.2.1. Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "judaeH_yc_N8"
   },
   "source": [
    "<p style=\"text-align: justify\">The artificial neural network (ANN) architecture comprises a sequential structure with:</p>\n",
    "<ul>\n",
    "    <li>one input layer (102 input nodes);</li>\n",
    "    <li>three hidden layers (204, 204 and 102 nodes, respectively);</li>\n",
    "    <li>one seven-node output layer.</li>\n",
    "</ul>\n",
    "<p style=\"text-align: justify\">As features are standardized real numbers, '<b>relu</b>' is elected as the activation function of choice for hidden layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1LieiZLc_N8"
   },
   "source": [
    "<img src=\"https://i.imgur.com/XcKIjmy.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "ann_classifier = Sequential()\n",
    "\n",
    "# Input layer and first dense layer\n",
    "ann_classifier.add(Dense(units = 204, kernel_initializer = 'uniform', activation = 'relu', input_dim = 102))\n",
    "ann_classifier.add(Dropout(0.1))\n",
    "\n",
    "# Second dense layer\n",
    "ann_classifier.add(Dense(units = 204, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "ann_classifier.add(Dropout(0.1))\n",
    "\n",
    "# Third dense layer\n",
    "ann_classifier.add(Dense(units = 102, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "ann_classifier.add(Dropout(0.1))\n",
    "\n",
    "# Output layer\n",
    "ann_classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Model compilation\n",
    "\n",
    "optim = Adam(learning_rate=0.0005)\n",
    "\n",
    "ann_classifier.compile(optimizer = optim, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_train_history = ann_classifier.fit(X_train, y_train_ann, batch_size = 32, epochs = 30, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEVymBxcc_N8"
   },
   "source": [
    "#### 6.2.2. Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-RglsLuc_N9"
   },
   "source": [
    "<p style=\"text-align: justify\">Training accuracy and loss per training epoch are charted below.</p>\n",
    "<p style=\"text-align: justify\">As we are dealing with hundreds of thousands of observations, it is not unusual to see a neural network model converging fast. In this case, batches contain 64 observations. In every epoch the model will be exposed to more than 5,000 different batches. Few epochs may suffice to lead to high accuracy, low loss levels already in the beginning of the training session.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7mEERltc_N9"
   },
   "source": [
    "#### 6.2.3. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uncnjkdyc_N9"
   },
   "source": [
    "<p style=\"text-align: justify\">After fitting the model to the training set, predictions are generated for the testing set. As a reminder, each prediction will correspond to an array with seven elements, each of them referring to one particular crop class. The final array is '<b>binarized</b>': the array element with the highest value will be converted to '1' while all other array elements will be converted to '0'.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZbwJ8eQTreV"
   },
   "outputs": [],
   "source": [
    "y_pred_ann = ann_classifier.predict(X_test)\n",
    "for i in range(len(y_pred_ann)):\n",
    "    for j in range(7):\n",
    "        if y_pred_ann[i][j] == y_pred_ann[i].max():\n",
    "            y_pred_ann[i][j] = 1\n",
    "        else:\n",
    "            y_pred_ann[i][j] = 0\n",
    "y_pred_ann = y_pred_ann.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeGn_OmMc_N9"
   },
   "source": [
    "<p style=\"text-align: justify\">A new sanity check reveals that the first prediction in the 'y_pred_ann' tensor matches the array generated for the first test set label - the class has been correctly predicted for this particular observation with our neural network.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdDtZ8CIc_N9",
    "outputId": "4b04f5c8-6681-43af-b579-191a76521402"
   },
   "outputs": [],
   "source": [
    "print(f'Predicted: {y_pred_ann[0]}')\n",
    "print(f'Actual: {y_test_ann[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGzS1D9Wc_N9"
   },
   "source": [
    "## 7. Classification performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxsd8hErc_N9"
   },
   "source": [
    "Performance is herein evaluated with both statistical metrics and confusion matrices. As a reminder, in confusion matrices:</p>\n",
    "<ul>\n",
    "    <li>Columns correspond to <b>predicted</b> classes;</li>\n",
    "    <li>Rows correspond to <b>actual</b> classes.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lymGnh2qa7Rp"
   },
   "outputs": [],
   "source": [
    "ann_cm = np.zeros((7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbQRnsPi5dsR"
   },
   "outputs": [],
   "source": [
    "ann_pred_correct = 0\n",
    "ann_pred_incorrect = 0\n",
    "for i in range(len(y_test_ann)):\n",
    "    if y_pred_ann[i].sum() > 0:\n",
    "        ann_index_test = np.where(y_test_ann[i] == 1)[0][0]\n",
    "        ann_index_pred = np.where(y_pred_ann[i] == 1)[0][0]\n",
    "        ann_cm[ann_index_test][ann_index_pred] += 1\n",
    "        if ann_index_test == ann_index_pred:\n",
    "            ann_pred_correct += 1\n",
    "        else:\n",
    "            ann_pred_incorrect += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wSINLMq5fYl",
    "outputId": "f38088c0-a17b-4365-f862-7ba2952c7daa"
   },
   "outputs": [],
   "source": [
    "ann_cmatrix = pd.DataFrame(ann_cm.astype(int),\n",
    "                           index = ['Corn', 'Pea', 'Canola', 'Soy', 'Oat', 'Wheat', 'Broadleaf'],\n",
    "                           columns = ['Corn', 'Pea', 'Canola', 'Soy', 'Oat', 'Wheat', 'Broadleaf'])\n",
    "ann_cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78fgfnt99klO",
    "outputId": "e55dad9a-485f-4b8a-cd9a-91e0604cfe91"
   },
   "outputs": [],
   "source": [
    "ann_accuracy = accuracy_score(y_test_ann, y_pred_ann)\n",
    "ann_precision, ann_recall, ann_f_score, ann_support = precision_recall_fscore_support(y_test_ann, y_pred_ann, average='macro')\n",
    "print(f'Accuracy: {ann_accuracy * 100:.2f} %')\n",
    "print(f'Precision: {ann_precision * 100:.2f} %')\n",
    "print(f'Recall: {ann_recall * 100:.2f} %')\n",
    "print(f'F-Score: {ann_f_score * 100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbRB5llvc_N-",
    "outputId": "a6082b0d-644e-4329-eed5-fd9e87762309"
   },
   "outputs": [],
   "source": [
    "print('Accuracy per class\\n')\n",
    "for i in range(len(ann_cmatrix)):\n",
    "    class_accuracy = ann_cmatrix.iloc[i,i] / ann_cmatrix.sum(axis=0)[i]\n",
    "    print(f'{ann_cmatrix.columns[i]}: {class_accuracy*100:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
