{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#eb3483'> Principal Components Analysis - Exercise </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we are going to develop an classifier to identify handwritten digits. The dataset contains 1797 images of handwritten digits (the numbers 0 to 9). Each digit is represented by an 8$\\times$8 set of pixels that each contain a value between 0 and 16 indicating the darkness of the pixel. In this dataset, each image has been flattened into 64 (8 $\\times$ 8) features. Intuitively, we expect that the values in pixels that are close together in the image are likely to be correlated. We will therefore begin our analyses by performing **dimension reduction** using principal components. Once we have determined the best number of components, we will proceed to use these as features in a logistic regression classifier.\n",
    "\n",
    "Let's begin by importing and exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Part 1: Familiarise yourself with the data and its structure </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Part 2: Perform a PCA and determine the best number of PCs to keep </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Standardise the data column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Run a PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Determine the optimal number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> Part 3: Develop a classifier to identify handwritten digits  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use logistic regression to identify the digit in an image based on the features that we engineered using principal components analysis.\n",
    "\n",
    "First up, recall that logistic regression is can only handle a binary outcome variable. However, the outcome variable in our dataset (i.e. the digit) has 10 categories! To get around this, we will train a logistic model for each digit. In our first model, we will create a new target such that $y=1$ is the digit is a \"0\", and $y=0$ otherwise. In our second model, we set $y=1$ is the digit is a \"1\", and $y=0$ otherwise. And so on. This will give us 10 models. This is called a \"one-vs-all\" strategy for dealing with a multi-category outcome variable.\n",
    "\n",
    "To classify a new image, we will get the probabilities from all 10 models and assign the digit with the highest probability. \n",
    "\n",
    "\n",
    "Begin by randomly splitting the dataset into training and test sets, so that you will be able to assess its performance on unseen data. Then fit the models as described above using the training data. Finally assess the classifiers performance on new, unseen data (i.e. the test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Create a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Fit a logistic regression model for each digit using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Assess the performance of your classification strategy on the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
